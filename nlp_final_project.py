# -*- coding: utf-8 -*-
"""NLP_Final_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LEx9z3lty1q0E0yWHDuehuOzrnSJLZRR
"""

from google.colab import files
import pandas as pd

uploaded = files.upload()
df = pd.read_csv("sentimentdataset.csv")
df.head()

df.info()
print(df.isnull().sum())
print(df.columns)
df.head()

import matplotlib.pyplot as plt
sentiment_counts = df['Sentiment'].value_counts()

plt.figure(figsize=(8, 5))
sentiment_counts.plot(kind='bar', color=['skyblue', 'salmon', 'lightgreen'])
plt.title("Sentiment Distribution")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.xticks(rotation=0)
plt.show()

sentiment_proportions = sentiment_counts / len(df) * 100
print("Sentiment Proportions (%):\n", sentiment_proportions)

platform_sentiment = df.groupby(['Platform', 'Sentiment']).size().unstack()

platform_sentiment.plot(kind='bar', figsize=(10, 6), stacked=True, colormap='viridis')
plt.title("Sentiment Distribution Across Platforms")
plt.xlabel("Platform")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.legend(title="Sentiment")
plt.show()

print("Platform-Based Sentiment Counts:\n", platform_sentiment)

import seaborn as sns

plt.figure(figsize=(10, 5))
sns.boxplot(data=df, x='Sentiment', y='Retweets', palette='Set2')
plt.title("Retweets by Sentiment")
plt.show()

plt.figure(figsize=(10, 5))
sns.boxplot(data=df, x='Sentiment', y='Likes', palette='Set3')
plt.title("Likes by Sentiment")
plt.show()

engagement_summary = df.groupby('Sentiment')[['Retweets', 'Likes']].mean()
print("Average Retweets and Likes by Sentiment:\n", engagement_summary)

import matplotlib.pyplot as plt

engagement_summary = df.groupby('Sentiment')[['Retweets', 'Likes']].mean()

plt.figure(figsize=(12, 6))
engagement_summary['Retweets'].sort_values(ascending=False).head(20).plot(kind='bar', color='skyblue')
plt.title("Top 20 Sentiments by Average Retweets")
plt.xlabel("Sentiment")
plt.ylabel("Average Retweets")
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(12, 6))
engagement_summary['Likes'].sort_values(ascending=False).head(20).plot(kind='bar', color='lightgreen')
plt.title("Top 20 Sentiments by Average Likes")
plt.xlabel("Sentiment")
plt.ylabel("Average Likes")
plt.xticks(rotation=45)
plt.show()

sentiment_counts = df['Sentiment'].value_counts()
print(sentiment_counts)

sentiment_mapping = {
    'Positive': 'Positive',
    'Joy': 'Positive',
    'Excitement': 'Positive',
    'Contentment': 'Positive',
    'Admiration': 'Positive',
    'Motivation': 'Positive',
    'Harmony': 'Positive',
    'Love': 'Positive',
    'Radiance': 'Positive',
    'Sadness': 'Negative',
    'Disappointment': 'Negative',
    'Fear': 'Negative',
    'Frustration': 'Negative',
    'Anger': 'Negative',
    'Neutral': 'Neutral',
    'Indifference': 'Neutral',
}

default_category = 'Neutral'

unmapped_sentiments = df[~df['Sentiment'].isin(sentiment_mapping.keys())]['Sentiment'].unique()
print("Unmapped Sentiments:\n", unmapped_sentiments)

sentiment_mapping = {
    'Positive': 'Positive',
    'Joy': 'Positive',
    'Excitement': 'Positive',
    'Contentment': 'Positive',
    'Happiness': 'Positive',
    'Admiration': 'Positive',
    'Motivation': 'Positive',
    'Love': 'Positive',
    'Amusement': 'Positive',
    'Gratitude': 'Positive',
    'Anticipation': 'Positive',
    'Euphoria': 'Positive',
    'Wonder': 'Positive',
    'Pride': 'Positive',
    'Harmony': 'Positive',
    'Thrill': 'Positive',
    'Enthusiasm': 'Positive',
    'Inspiration': 'Positive',
    'Satisfaction': 'Positive',
    'Negative': 'Negative',
    'Anger': 'Negative',
    'Fear': 'Negative',
    'Sadness': 'Negative',
    'Disgust': 'Negative',
    'Frustration': 'Negative',
    'Disappointment': 'Negative',
    'Despair': 'Negative',
    'Grief': 'Negative',
    'Heartbreak': 'Negative',
    'Loneliness': 'Negative',
    'Jealousy': 'Negative',
    'Anxiety': 'Negative',
    'Resentment': 'Negative',
    'Boredom': 'Negative',
    'Helplessness': 'Negative',
    'Regret': 'Negative',
    'Betrayal': 'Negative',
    'Sorrow': 'Negative',
    'Neutral': 'Neutral',
    'Indifference': 'Neutral',
    'Calmness': 'Neutral',
    'Serenity': 'Neutral',
    'Ambivalence': 'Neutral',
    'Curiosity': 'Neutral',
    'Acceptance': 'Neutral',
}

default_category = 'Neutral'

df['Refined_Sentiment'] = df['Sentiment'].map(sentiment_mapping).fillna(default_category)

print("Refined Sentiment Distribution:\n", df['Refined_Sentiment'].value_counts())

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
df['Refined_Sentiment'].value_counts().plot(kind='bar', color=['skyblue', 'salmon', 'lightgreen'])
plt.title("Refined Sentiment Distribution")
plt.xlabel("Refined Sentiment")
plt.ylabel("Count")
plt.xticks(rotation=0)
plt.show()

unmapped_sentiments = df[~df['Sentiment'].isin(sentiment_mapping.keys())]['Sentiment'].unique()
print("Unmapped Sentiments:\n", unmapped_sentiments)

def map_sentiment(sentiment):
    sentiment = sentiment.strip().lower()
    if any(word in sentiment for word in [
        'positive', 'joy', 'happiness', 'love', 'gratitude', 'excite',
        'admiration', 'pride', 'satisfaction', 'inspiration', 'wonder',
        'calmness', 'serenity', 'euphoria', 'thrill', 'motivation',
        'anticipation', 'amusement', 'playful', 'optimism'
    ]):
        return 'Positive'

    elif any(word in sentiment for word in [
        'negative', 'anger', 'fear', 'sad', 'frustration', 'anxiety',
        'disappointment', 'despair', 'grief', 'loneliness', 'regret',
        'betrayal', 'sorrow', 'melancholy', 'resentment', 'boredom',
        'jealousy', 'helplessness', 'disgust'
    ]):
        return 'Negative'

    elif any(word in sentiment for word in [
        'neutral', 'indifference', 'numbness', 'ambivalence', 'calmness'
    ]):
        return 'Neutral'

    return 'Neutral'

df['Refined_Sentiment'] = df['Sentiment'].apply(map_sentiment)

print("Refined Sentiment Distribution:\n", df['Refined_Sentiment'].value_counts())

import matplotlib.pyplot as plt
plt.figure(figsize=(8, 5))
df['Refined_Sentiment'].value_counts().plot(kind='bar', color=['skyblue', 'salmon', 'lightgreen'])
plt.title("Refined Sentiment Distribution")
plt.xlabel("Refined Sentiment")
plt.ylabel("Count")
plt.xticks(rotation=0)
plt.show()

# Install NLTK if not already installed
!pip install nltk

# Import libraries
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import nltk

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

import nltk
import shutil

# Remove existing nltk_data to clean up any corrupted downloads
shutil.rmtree('/root/nltk_data', ignore_errors=True)

# Redownload necessary resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

import re

# Define a simplified text preprocessing function
def preprocess_text_simple(text):
    # Convert text to lowercase
    text = text.lower()
    # Remove URLs
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)
    # Remove mentions and hashtags
    text = re.sub(r'\@\w+|\#', '', text)
    # Remove special characters, numbers, and punctuation
    text = re.sub(r"[^a-zA-Z\s]", '', text)
    # Remove extra spaces
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Apply the function to the dataset
df['Cleaned_Text'] = df['Text'].apply(preprocess_text_simple)

# Verify results
print(df[['Text', 'Cleaned_Text']].head())

from collections import Counter
import matplotlib.pyplot as plt

# Tokenize the cleaned text
all_words = ' '.join(df['Cleaned_Text']).split()

# Count word frequencies
word_freq = Counter(all_words)
common_words = word_freq.most_common(20)

# Convert to a DataFrame for visualization
common_words_df = pd.DataFrame(common_words, columns=['Word', 'Frequency'])

# Plot the most common words
plt.figure(figsize=(10, 6))
plt.bar(common_words_df['Word'], common_words_df['Frequency'], color='skyblue')
plt.title('Top 20 Most Common Words')
plt.xlabel('Word')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

from wordcloud import WordCloud

# Generate a word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(all_words))

# Display the word cloud
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of Cleaned Text')
plt.show()

# Calculate text lengths
df['Text_Length'] = df['Cleaned_Text'].apply(len)

# Plot text length distribution
plt.figure(figsize=(10, 6))
plt.hist(df['Text_Length'], bins=20, color='salmon', alpha=0.7)
plt.title('Distribution of Text Lengths')
plt.xlabel('Text Length')
plt.ylabel('Frequency')
plt.show()

# Calculate average text length by sentiment
avg_text_length = df.groupby('Refined_Sentiment')['Text_Length'].mean()

# Plot average text length by sentiment
avg_text_length.plot(kind='bar', color=['skyblue', 'salmon', 'lightgreen'], figsize=(8, 5))
plt.title('Average Text Length by Sentiment')
plt.xlabel('Refined Sentiment')
plt.ylabel('Average Text Length')
plt.xticks(rotation=0)
plt.show()

# Tokenize and count word frequencies by sentiment
for sentiment in df['Refined_Sentiment'].unique():
    sentiment_words = ' '.join(df[df['Refined_Sentiment'] == sentiment]['Cleaned_Text']).split()
    sentiment_word_freq = Counter(sentiment_words).most_common(10)
    print(f"Top words for {sentiment} sentiment:\n", sentiment_word_freq, "\n")

from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

# Remove stopwords from cleaned text
def remove_stopwords(text):
    words = text.split()
    filtered_words = [word for word in words if word not in ENGLISH_STOP_WORDS]
    return ' '.join(filtered_words)

# Apply stopword removal
df['Cleaned_Text_NoStopwords'] = df['Cleaned_Text'].apply(remove_stopwords)

# Verify the changes
print(df[['Cleaned_Text', 'Cleaned_Text_NoStopwords']].head())

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=500, stop_words='english')  # Limiting to top 500 features for simplicity

# Fit and transform the cleaned text
tfidf_matrix = tfidf_vectorizer.fit_transform(df['Cleaned_Text_NoStopwords'])

# Convert to a DataFrame for easier visualization
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

# Display the TF-IDF DataFrame
print(tfidf_df.head())

# Save features and labels
tfidf_df['Refined_Sentiment'] = df['Refined_Sentiment']
tfidf_df.to_csv("tfidf_features.csv", index=False)

print("TF-IDF features saved as tfidf_features.csv")

from sklearn.decomposition import TruncatedSVD

# Apply Truncated SVD to reduce dimensions
svd = TruncatedSVD(n_components=100, random_state=42)  # Reduce to 100 features
tfidf_reduced = svd.fit_transform(tfidf_matrix)

# Convert reduced matrix to DataFrame for easier use
reduced_df = pd.DataFrame(tfidf_reduced, columns=[f"Component_{i}" for i in range(1, 101)])

# Add the target variable back to the reduced DataFrame
reduced_df['Refined_Sentiment'] = df['Refined_Sentiment']

# Save the reduced feature set
reduced_df.to_csv("reduced_tfidf_features.csv", index=False)
print("Reduced TF-IDF features saved as reduced_tfidf_features.csv")

# Add text length
df['Text_Length'] = df['Cleaned_Text_NoStopwords'].apply(len)

# Add word count
df['Word_Count'] = df['Cleaned_Text_NoStopwords'].apply(lambda x: len(x.split()))

# Combine with reduced TF-IDF features
reduced_df['Text_Length'] = df['Text_Length']
reduced_df['Word_Count'] = df['Word_Count']

# Save the enhanced feature set
reduced_df.to_csv("enhanced_tfidf_features.csv", index=False)
print("Enhanced features saved as enhanced_tfidf_features.csv")

from textblob import TextBlob

# Calculate numerical features
df['Polarity'] = df['Text'].apply(lambda x: TextBlob(x).sentiment.polarity)
df['Subjectivity'] = df['Text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)
df['Text_Length'] = df['Text'].apply(len)
df['Word_Count'] = df['Text'].apply(lambda x: len(x.split()))

from sklearn.feature_extraction.text import TfidfVectorizer

# Vectorize the text using TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=500)  # Adjust max_features as needed
tfidf_matrix = tfidf_vectorizer.fit_transform(df['Text'])

from sklearn.decomposition import PCA

# Apply PCA to reduce dimensions
pca = PCA(n_components=100, random_state=42)  # Adjust n_components as needed
tfidf_reduced = pca.fit_transform(tfidf_matrix.toarray())

import numpy as np

# Combine numerical and TF-IDF features
numerical_features = df[['Polarity', 'Subjectivity', 'Text_Length', 'Word_Count']].values
combined_features = np.hstack([numerical_features, tfidf_reduced])

print("Combined Feature Shape:", combined_features.shape)

print(df.columns)

from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

# Convert sklearn stopwords set to a list
stop_words = list(ENGLISH_STOP_WORDS)

import re
import string

def preprocess_text(text):
    # Lowercase the text
    text = text.lower()

    # Remove URLs
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)

    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))

    # Remove numbers
    text = re.sub(r'\d+', '', text)

    # Tokenize and remove stopwords
    tokens = text.split()
    filtered_tokens = [word for word in tokens if word not in stop_words]

    # Return the cleaned text
    return " ".join(filtered_tokens)

# Assuming 'Text' column contains raw text data
df['Cleaned_Text'] = df['Text'].apply(preprocess_text)

# Display a sample
print(df[['Text', 'Cleaned_Text']].head())

def preprocess_text(text):
    # Lowercase the text
    text = text.lower()

    # Remove URLs
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)

    # Remove punctuation and special characters
    text = re.sub(r'[^\w\s]', '', text)

    # Remove numbers
    text = re.sub(r'\d+', '', text)

    # Tokenize and remove stopwords
    tokens = text.split()
    filtered_tokens = [word for word in tokens if word not in stop_words]

    # Return the cleaned text
    return " ".join(filtered_tokens)

from collections import Counter
import matplotlib.pyplot as plt

# Combine all cleaned text into a single string
all_text = " ".join(df['Cleaned_Text'])

# Split the text into words
words = all_text.split()

# Count word frequencies
word_counts = Counter(words)
most_common_words = word_counts.most_common(10)

# Convert to a DataFrame for easier plotting
common_words_df = pd.DataFrame(most_common_words, columns=['Word', 'Frequency'])

# Plot the most frequent words
plt.figure(figsize=(10, 6))
plt.bar(common_words_df['Word'], common_words_df['Frequency'])
plt.title("Top 10 Most Frequent Words")
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.xticks(rotation=45)
plt.show()

common_words_df

from gensim.models import Word2Vec
import numpy as np

# Step 1: Tokenize the text into a list of sentences
tokenized_sentences = df['Cleaned_Text'].apply(lambda x: x.split())

# Step 2: Train a Word2Vec model
word2vec_model = Word2Vec(
    sentences=tokenized_sentences,
    vector_size=100,  # Dimensionality of the word vectors
    window=5,         # Context window size
    min_count=1,      # Minimum frequency count of words
    workers=4         # Number of parallel threads
)

# Step 3: Generate document embeddings
def get_avg_word2vec(tokens, model, vector_size):
    """Generate average Word2Vec embedding for a document."""
    if len(tokens) < 1:
        return np.zeros(vector_size)
    vectors = [model.wv[word] for word in tokens if word in model.wv]
    if len(vectors) == 0:
        return np.zeros(vector_size)
    return np.mean(vectors, axis=0)

df['Word2Vec_Embedding'] = tokenized_sentences.apply(
    lambda tokens: get_avg_word2vec(tokens, word2vec_model, 100)
)

# Check the results
print("Sample Word2Vec Embedding:")
print(df['Word2Vec_Embedding'].head())

from sklearn.model_selection import train_test_split
import numpy as np

# Convert the Word2Vec embeddings into a usable feature matrix
X_word2vec = np.stack(df['Word2Vec_Embedding'].values)
y_labels = df['Refined_Sentiment']

# Split the dataset into training and testing sets
X_train_word2vec, X_test_word2vec, y_train, y_test = train_test_split(
    X_word2vec, y_labels, test_size=0.2, random_state=42, stratify=y_labels
)

# Check the shapes of the training and testing sets
X_train_word2vec.shape, X_test_word2vec.shape, len(y_train), len(y_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Initialize and train the Logistic Regression model
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train_word2vec, y_train)

# Evaluate on the test set
y_test_pred = model.predict(X_test_word2vec)
test_accuracy = accuracy_score(y_test, y_test_pred)

# Print accuracy
print(f"Test Accuracy: {test_accuracy:.4f}")

# Classification report
print("Classification Report:\n", classification_report(y_test, y_test_pred))

from imblearn.over_sampling import RandomOverSampler
from collections import Counter

# Apply random oversampling
oversampler = RandomOverSampler(random_state=42)
X_train_balanced, y_train_balanced = oversampler.fit_resample(X_train_word2vec, y_train)

# Check the class distribution
print("Class distribution after random oversampling:", Counter(y_train_balanced))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Train logistic regression on balanced data
logistic_model = LogisticRegression(random_state=42, max_iter=1000)
logistic_model.fit(X_train_balanced, y_train_balanced)

# Evaluate on the test set
y_pred = logistic_model.predict(X_test_word2vec)

# Print performance metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')  # Adjust max_features as needed
X_tfidf = tfidf_vectorizer.fit_transform(df['Cleaned_Text']).toarray()

import numpy as np

additional_features = df[['Polarity', 'Subjectivity', 'Text_Length', 'Word_Count']].values
X_combined = np.hstack((X_tfidf, additional_features))

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_combined, df['Refined_Sentiment'])

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)
model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.metrics import confusion_matrix, classification_report
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

model = LogisticRegression(max_iter=500)  # Default is 100

y_combined = y_resampled  # Use the oversampled labels if applicable

print(X_combined.shape, len(y_combined))

y_original = df['Refined_Sentiment']
print(y_original.shape)

y_original = y_original.iloc[:X_combined.shape[0]]

y_combined = y_original

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression

# Define the model
model = LogisticRegression(max_iter=1000, random_state=42)

# Perform cross-validation
scores = cross_val_score(model, X_combined, y_combined, cv=5, scoring='accuracy')
print("Cross-Validation Accuracy (increased iterations): ", scores.mean())

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.utils import shuffle
from sklearn.exceptions import ConvergenceWarning
import warnings

# Suppress warnings
warnings.filterwarnings("ignore", category=ConvergenceWarning)

# Assuming X_combined and y_combined are defined
# Shuffle the data to ensure randomness
X_combined, y_combined = shuffle(X_combined, y_combined, random_state=42)

# Define pipeline for preprocessing and model training
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # Scale the features
    ('logreg', LogisticRegression(solver='lbfgs', max_iter=2000, random_state=42))
])

# Perform cross-validation
cv_scores = cross_val_score(pipeline, X_combined, y_combined, cv=5, scoring='accuracy')

# Output the cross-validation accuracy
print("Cross-Validation Accuracy (Logistic Regression):", cv_scores.mean())

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

# Assuming X_train contains raw features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# Initialize the Logistic Regression model
model = LogisticRegression(max_iter=1000, random_state=42)

# Fit the model
model.fit(X_train_scaled, y_train)

# Confirm successful fitting
print("Model fitted successfully.")

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler

# Scale the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize the Logistic Regression model with class_weight='balanced'
balanced_model = LogisticRegression(
    solver='lbfgs',
    max_iter=1000,
    class_weight='balanced',
    random_state=42
)

# Fit the model on the training data
balanced_model.fit(X_train_scaled, y_train)

# Evaluate on the test data
test_accuracy = balanced_model.score(X_test_scaled, y_test)
y_test_pred = balanced_model.predict(X_test_scaled)

# Print results
print("Test Accuracy (with balanced class weights):", test_accuracy)
print("Classification Report (with balanced class weights):\n", classification_report(y_test, y_test_pred))

# Plot confusion matrix
cm = confusion_matrix(y_test, y_test_pred, labels=balanced_model.classes_)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=balanced_model.classes_, yticklabels=balanced_model.classes_)
plt.title("Confusion Matrix (with balanced class weights)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

import joblib
joblib.dump(balanced_model, 'balanced_logistic_regression_model.pkl')
print("Model saved successfully.")

from sklearn.metrics import roc_curve, roc_auc_score

y_test_probs = balanced_model.predict_proba(X_test_scaled)
for i, class_label in enumerate(balanced_model.classes_):
    fpr, tpr, _ = roc_curve((y_test == class_label).astype(int), y_test_probs[:, i])
    auc_score = roc_auc_score((y_test == class_label).astype(int), y_test_probs[:, i])
    plt.plot(fpr, tpr, label=f"Class {class_label} (AUC = {auc_score:.2f})")

plt.plot([0, 1], [0, 1], 'k--', label="Random")
plt.title("One-vs-All ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

import joblib

# Load the saved model
loaded_model = joblib.load('balanced_logistic_regression_model.pkl')
print("Model loaded successfully.")

from google.colab import files

# Upload your dataset
uploaded = files.upload()

# Load the dataset
import pandas as pd
dataset = pd.read_csv("sentimentdataset.csv")

!pip install transformers datasets torch scikit-learn

# Simplify sentiment labels
def simplify_sentiment(sentiment):
    sentiment = sentiment.strip().lower()
    if sentiment in ["positive", "happiness", "joy", "excitement", "gratitude", "love", "admiration"]:
        return 0  # Positive
    elif sentiment in ["negative", "anger", "fear", "sadness", "frustration", "disgust", "regret"]:
        return 1  # Negative
    elif sentiment in ["neutral", "calmness", "indifference"]:
        return 2  # Neutral
    else:
        return None

# Apply the mapping
dataset['Sentiment'] = dataset['Sentiment'].apply(simplify_sentiment)
dataset = dataset.dropna(subset=['Sentiment'])

# Split data
from sklearn.model_selection import train_test_split
train_data, test_data = train_test_split(dataset[['Text', 'Sentiment']], test_size=0.2, random_state=42)

from transformers import AutoTokenizer

# Load tokenizer
model_name = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Tokenize the dataset
def tokenize_data(batch):
    return tokenizer(batch['Text'], padding=True, truncation=True, max_length=256)

train_data = train_data.reset_index(drop=True)
test_data = test_data.reset_index(drop=True)

train_data_tokenized = tokenizer(list(train_data['Text']), truncation=True, padding=True, max_length=256)
test_data_tokenized = tokenizer(list(test_data['Text']), truncation=True, padding=True, max_length=256)

import torch
from torch.utils.data import DataLoader, Dataset

class SentimentDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SentimentDataset(train_data_tokenized, list(train_data['Sentiment']))
test_dataset = SentimentDataset(test_data_tokenized, list(test_data['Sentiment']))

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16)

class SentimentDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Ensure long type for CrossEntropyLoss
        return item

    def __len__(self):
        return len(self.labels)

print(train_dataset[0]['labels'])  # Should output an integer: 0, 1, or 2

class SentimentDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        # Convert labels to long (integer type)
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

    def __len__(self):
        return len(self.labels)

print(train_dataset[0]['labels'])  # Should print an integer: 0, 1, or 2
print(type(train_dataset[0]['labels']))  # Should print <class 'torch.Tensor'>

# Example: Convert labels to integers explicitly before creating datasets
train_labels = [int(label) for label in train_data['Sentiment']]
test_labels = [int(label) for label in test_data['Sentiment']]

train_dataset = SentimentDataset(train_data_tokenized, train_labels)
test_dataset = SentimentDataset(test_data_tokenized, test_labels)

from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=3)

# Convert labels to integers explicitly
train_labels = train_data['Sentiment'].astype(int).tolist()
test_labels = test_data['Sentiment'].astype(int).tolist()

# Update the dataset creation
train_dataset = SentimentDataset(train_data_tokenized, train_labels)
test_dataset = SentimentDataset(test_data_tokenized, test_labels)

print(train_dataset[0]['labels'])  # Should print 0, 1, or 2 as an integer
print(type(train_dataset[0]['labels']))  # Should print <class 'torch.Tensor'>

from transformers import AutoModelForSequenceClassification

model_name = "distilbert-base-uncased"
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Ensure num_labels=3

# Test the model's forward pass with a batch
batch = next(iter(DataLoader(train_dataset, batch_size=16)))
outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])

# Check the output logits and loss
print("Logits shape:", outputs.logits.shape)  # Should be [batch_size, num_labels]
print("Loss:", outputs.loss)  # Should compute without errors

from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="epoch",  # Correct name for newer versions
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    save_total_limit=2,
    logging_dir="./logs",
    report_to="none",  # Disable logging integrations
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)

trainer.train()

# Evaluate on test data
metrics = trainer.evaluate()
print(metrics)

from transformers import pipeline

# Load the pipeline for sentiment analysis
sentiment_analysis = pipeline("text-classification", model=model, tokenizer=tokenizer)

# Test the model on custom examples
examples = [
    "This is the best day of my life!",
    "I am very disappointed with this product.",
    "It's an okay experience, not too bad, not too great."
]

results = sentiment_analysis(examples)
for example, result in zip(examples, results):
    print(f"Text: {example}\nPrediction: {result['label']} (Score: {result['score']:.4f})\n")

model.save_pretrained("./saved_model")
tokenizer.save_pretrained("./saved_model")

from transformers import AutoModelForSequenceClassification, AutoTokenizer

loaded_model = AutoModelForSequenceClassification.from_pretrained("./saved_model")
loaded_tokenizer = AutoTokenizer.from_pretrained("./saved_model")

# Check the id2label mapping
print(model.config.id2label)

# Evaluate the model
metrics = trainer.evaluate()
print(metrics)

label_mapping = {0: "Positive", 1: "Negative", 2: "Neutral"}

examples = [
    "This is the best day of my life!",
    "I am very disappointed with this product.",
    "It's an okay experience, not too bad, not too great."
]

# Perform sentiment analysis
results = sentiment_analysis(examples)

# Map labels and display results
for example, result in zip(examples, results):
    sentiment = label_mapping[int(result['label'].split('_')[1])]  # Extract integer label
    print(f"Text: {example}\nPrediction: {sentiment} (Score: {result['score']:.4f})\n")

from sklearn.metrics import classification_report
import numpy as np

# Get predictions and true labels
preds = trainer.predict(test_dataset)
y_pred = np.argmax(preds.predictions, axis=1)  # Predicted labels
y_true = test_data['Sentiment'].tolist()       # True labels

# Generate classification report
print(classification_report(y_true, y_pred, target_names=["Positive", "Negative", "Neutral"]))

# Convert to torch tensor and use CPU
class_weights = torch.tensor(class_weights, dtype=torch.float).to("cpu")  # or simply omit .to("cpu")
print("Class weights:", class_weights)

from transformers import DistilBertForSequenceClassification
import torch.nn as nn

# Load the pre-trained model
model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=3)

# Custom model wrapper to include class weights
class CustomLossModel(nn.Module):
    def __init__(self, model, class_weights):
        super(CustomLossModel, self).__init__()
        self.model = model
        self.class_weights = class_weights
        self.loss_fn = nn.CrossEntropyLoss(weight=self.class_weights)

    def forward(self, input_ids, attention_mask, labels):
        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        loss = self.loss_fn(logits, labels)
        return {"loss": loss, "logits": logits}

# Wrap the model with the custom loss
custom_model = CustomLossModel(model, class_weights)

from transformers import Trainer, TrainingArguments

training_args = TrainingArguments(
    output_dir="./results",
    eval_strategy="epoch",
    learning_rate=1e-5,  # Fine-tuned learning rate
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=5,  # Increase epochs for better performance
    weight_decay=0.01,
    save_total_limit=2,
    logging_dir="./logs",
    report_to="none",  # Disable logging integrations
)

# Use the custom model
trainer = Trainer(
    model=custom_model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)

trainer.train()

from sklearn.metrics import classification_report
import numpy as np

# Evaluate the model
preds = trainer.predict(test_dataset)
y_pred = np.argmax(preds.predictions, axis=1)
y_true = test_data['Sentiment'].tolist()

# Generate classification report
print(classification_report(y_true, y_pred, target_names=["Positive", "Negative", "Neutral"]))

examples = [
    "I absolutely love this product!",
    "The experience was terrible and disappointing.",
    "It's just okay, nothing special.",
    "Amazing service! Highly recommended.",
    "The quality of this item is very poor."
]

results = sentiment_analysis(examples)
for example, result in zip(examples, results):
    print(f"Text: {example}\nPrediction: {result['label']} (Score: {result['score']:.4f})\n")

examples = [
    "I had the worst experience ever.",
    "This product is amazing and works perfectly!",
    "It's okay, not great but not bad either.",
    "Highly disappointed with the quality.",
    "Very neutral feeling about this decision."
]
results = sentiment_analysis(examples)
for example, result in zip(examples, results):
    print(f"Text: {example}\nPrediction: {result['label']} (Score: {result['score']:.4f})\n")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Positive", "Negative", "Neutral"])
disp.plot(cmap="Blues")

# Save the model and tokenizer
model.save_pretrained("./sentiment_model")
tokenizer.save_pretrained("./sentiment_model")

from transformers import AutoModelForSequenceClassification, AutoTokenizer

model = AutoModelForSequenceClassification.from_pretrained("./sentiment_model")
tokenizer = AutoTokenizer.from_pretrained("./sentiment_model")

import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load dataset
X = train_data['Text']
y = train_data['Sentiment']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tokenize text
max_words = 5000  # Vocabulary size
max_len = 100     # Maximum sequence length

tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

# Convert text to sequences
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Pad sequences
X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')

from tensorflow.keras.utils import to_categorical

# One-hot encode the labels
y_train_onehot = to_categorical(y_train, num_classes=3)
y_test_onehot = to_categorical(y_test, num_classes=3)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

# Define the LSTM model
model = Sequential([
    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),  # Embedding layer
    LSTM(128, return_sequences=False),  # LSTM layer
    Dropout(0.3),  # Dropout for regularization
    Dense(64, activation='relu'),  # Fully connected layer
    Dropout(0.3),
    Dense(3, activation='softmax')  # Output layer for 3 classes
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

# Train the model
history = model.fit(
    X_train_pad, y_train_onehot,
    validation_data=(X_test_pad, y_test_onehot),
    epochs=15,
    batch_size=32
)

# Evaluate on test data
loss, accuracy = model.evaluate(X_test_pad, y_test_onehot)
print(f"LSTM Test Accuracy: {accuracy:.2f}")

# Make predictions
y_pred_probs = model.predict(X_test_pad)
y_pred = y_pred_probs.argmax(axis=1)

from sklearn.metrics import classification_report, confusion_matrix


# Convert predictions and labels correctly
y_test_labels = y_test.to_numpy()  # Convert y_test to NumPy array



# Classification report
print(classification_report(y_test_labels, y_pred, target_names=["Positive", "Negative", "Neutral"]))

from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch

# Load the saved model
model = AutoModelForSequenceClassification.from_pretrained("./sentiment_model")
tokenizer = AutoTokenizer.from_pretrained("./sentiment_model")

# Predict function
def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=256)
    outputs = model(**inputs)
    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
    predicted_label = torch.argmax(predictions, dim=1).item()
    labels = {0: "Positive", 1: "Negative", 2: "Neutral"}
    return labels[predicted_label], predictions[0][predicted_label].item()

# Test the function
text = "This is a great product!"
label, confidence = predict_sentiment(text)
print(f"Text: {text}\nLabel: {label}, Confidence: {confidence:.2f}")